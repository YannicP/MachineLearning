{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><b><font color=\"darkblue\">Kaggle - Titanic: Machine Learning from Desaster: 81.34 Accuracy (Top 6 %)</b></font> \n",
    "\n",
    "<font size=\"3\"><font color=\"#323231\"><i>Goal of this project was to reach a scoring above 80% on the famous kaggle \"Titanic\" dataset. This was achieved\n",
    "through careful feature engineering and using a 3 Layer Neural Network with Dropout and Batch Norm on this    augmented dataset.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>My first step was combining training and test dataset into one in order to have it easier to apply my transformations. To be able to seperate them later, I added a flag \"Set\" as a column to both data sources. I also saved the test sets \"PassengerId\" column, as this was needed later to build the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Set</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54.0</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>349909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>237736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "5   NaN   NaN        Q   8.4583   \n",
       "6  54.0   E46        S  51.8625   \n",
       "7   2.0   NaN        S  21.0750   \n",
       "8  27.0   NaN        S  11.1333   \n",
       "9  14.0   NaN        C  30.0708   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "5                                   Moran, Mr. James      0            6   \n",
       "6                            McCarthy, Mr. Timothy J      0            7   \n",
       "7                     Palsson, Master. Gosta Leonard      1            8   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      2            9   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)      0           10   \n",
       "\n",
       "   Pclass    Set     Sex  SibSp  Survived            Ticket  \n",
       "0       3  train    male      1         0         A/5 21171  \n",
       "1       1  train  female      1         1          PC 17599  \n",
       "2       3  train  female      0         1  STON/O2. 3101282  \n",
       "3       1  train  female      1         1            113803  \n",
       "4       3  train    male      0         0            373450  \n",
       "5       3  train    male      0         0            330877  \n",
       "6       1  train    male      0         0             17463  \n",
       "7       3  train    male      3         0            349909  \n",
       "8       3  train  female      0         1            347742  \n",
       "9       2  train  female      1         1            237736  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"datasets/titanic/train.csv\")\n",
    "test = pd.read_csv(\"datasets/titanic/test.csv\")\n",
    "passenger_ids = test[\"PassengerId\"]\n",
    "test[\"Survived\"] = 0\n",
    "test[\"Set\"] = \"test\"\n",
    "train[\"Set\"] = \"train\"\n",
    "data = train.append(test, sort=True)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 13 columns):\n",
      "Age            1046 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Set            1309 non-null object\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       1309 non-null int64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 143.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"><b><font color=\"darkblue\"> Step 1: Exploratory Data Analysis</b></font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>just from looking at the data, different conclusions can be drawn:\n",
    "- There are Missing values in the following columns: \"Age\", \"Cabin\" and \"Embarked\". Especially the \"Cabin\" column was missing most of it's entries. \n",
    "- Some columns contain strings and must first be converted into a more useful format.\n",
    "- Our labels are stored in the \"Survived\" column. Normally, there would be missing values for all the test set, but in our case, I decided to give those rows the label 0 as I needed that for a later transformation and after the whole process this column would be dropped from our test set anyways.\n",
    "- Every \"Cabin\" entry starts with a letter (A, B, C, D, E, F, G) followed by a number.\n",
    "- The \"Name\" column also stores some interesting information. From here it is possible to extract the passengers title e.g. \"Mr\", \"Mrs\", \"Lady\", \"Master\" ,... aswell as the last Name, that may be shared with other passengers.\n",
    "- The payed fares a widely variable and range from less than 10 to more than 150.\n",
    "    \n",
    "Let's further explore those observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAFCCAYAAADL6mj4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHtVJREFUeJzt3XtYlHX+//EXDIqpmWKAo6uiU+qkUppWrmWsupEJYq5Kseq6Jq55maXbJh3kYFpipeWpNlp1DV2NbD2A5WbappWmLVe6oq0HPBWCgqakoA737w+/zW8ndBkLPjj4fFxXF8zMZ+77PZJcT+/7HvCzLMsSAAAAqpR/dQ8AAABwLSC6AAAADCC6AAAADCC6AAAADCC6AAAADCC6AAAADCC6AFSJoUOHavLkyZW6zZ49e+ovf/nLZR+fPXu2oqKiKnWfV4vJkydr6NCh1T0GgJ8hoLoHAFA1ioqKNGvWLH3yyScqKChQgwYNdPPNN2vUqFHq3r17le9/9uzZCgioOd9iDh8+rDfeeEOfffaZjh07poYNG6pVq1YaMGCA+vbtq9q1a1f3iACucjXnOyIAD4899pjOnj2rqVOnqkWLFiosLNTWrVt18uTJn7Xdc+fOeRUYDRs2/Fn7uZrs2LFDw4cPl8Ph0HPPPafWrVurpKRE+/bt0zvvvKMWLVro9ttvr+4xK3T+/HnVqlWruscArlmcXgRqoFOnTmnbtm168skn1a1bNzVr1kzh4eF65JFH1LdvX/e6S52u+/FpwZ49e2r27Nl6+umn1aVLFz355JOKjY3VtGnTPJ5XXFys8PBwffjhh+W288orr2jAgAHl5nzooYc0ZcoUSdL27ds1YsQI3XnnnercubMefvhhZWdn/6TXn5GRoYiICIWHh2vMmDEqKiqSJG3dulXt27fXsWPHPNbPnDlT0dHRl9yWZVlKSEhQy5YttXTpUvXq1UutWrWS0+lUVFSUFi1apM6dO7vX5+fna/z48eratau6du2qUaNG6cCBA+7HfzgFmpWVpd69e6tTp04eM0qSy+VSamqqextTp06Vy+UqN1daWpp69+6t8PBwRUdHa+XKle7Hjxw5orZt2yozM1PDhg1TeHi4li1b9pP+PAFUDqILqIHq1q2runXrav369SotLf3Z21uwYIFat26t5cuXa8KECerXr5+ysrJUVlbmXrN27VrVqVNH9957b7nnx8TEaOfOndq3b5/7vsOHDys7O1v9+vWTJH3//ffq16+flixZooyMDDmdTo0aNcojRrzxzTffaNWqVZo3b54WLFiggwcP6plnnpEkde3aVc2bN9eKFSvc68vKyrRixQoNHDjwktvbtWuX9u7dq0ceeUT+/pf+lunn5ydJOnv2rIYNG6bAwEC9/fbbWrp0qYKDg/X73/9eZ8+e9ZhxzZo1mjNnjubPn69du3bp1VdfdT8+f/58vfPOO0pJSdHSpUtVVlam1atXe+zz1Vdf1bvvvqvExERlZWVp1KhRSkpK0scff+yxbsaMGYqLi3NHHoDqQ3QBNVBAQICmTZumVatWqUuXLoqNjVVqaqq++uqrn7S9O+64Q/Hx8WrZsqXCwsL0wAMP6MSJE9qyZYt7zerVq3X//fdf8tTjTTfdJKfT6REOq1evVlhYmMLDwyVJ3bp1U//+/eVwOORwODRp0iQFBgZq48aNVzRrSUmJUlNTdcstt+j2229XSkqKNmzY4D7aNGjQIL333nvu9Rs3blRhYaE7/n7sh+e1atXKfd/p06fVqVMn939vvPGGJCkrK0uWZenFF19Uu3bt5HA4NHnyZJ05c0YbNmxwP//ChQuaNm2a2rVrp06dOmnw4MH6/PPP3Y//9a9/1ciRI/XAAw/I4XDo2WefVXBwsPvxM2fOaMGCBZo6dap69Oih5s2bKzo6WoMGDdLixYs95h8yZIjuv/9+NW/eXE2aNLmiP0sAlYtruoAaKjIyUhEREdq2bZuys7O1adMmzZ8/X+PHj9fo0aOvaFsdOnTwuN2oUSPdfffdWrVqlbp166aCggJt2bJFY8eOvew2fjiK9cQTT0i6GF3/HTqFhYV67bXXtGXLFh0/flxlZWUqKSlRXl7eFc0aGhqqpk2bum/feuut8vf31759+xQWFqYHH3xQM2fO1L/+9S917txZy5cvV+/evdWoUSOv91GvXj330bJRo0bp/PnzkqSdO3fqyJEjHqcbpYtHwA4fPuy+3bRpU11//fXu2yEhISosLJR0MeiOHTum2267zf24v7+/wsPDdfToUUnS3r17VVpaqpEjR7qPskkXr9lq1qyZx75//LUDUH2ILqAGCwwMVPfu3dW9e3eNHTtWzz77rObMmaMRI0aodu3a8vPzk2VZHs/5ISD+23XXXVfuvn79+mnSpElKTk5WVlaW7Hb7/7yYPCoqSi+99JKys7NVu3Zt7d+/3yO6Jk6cqMLCQj399NNq1qyZateureHDh19ynp8jKChIPXv21PLly9WqVSutX7/efaTqUsLCwiRJ+/fv1y233CLpYgS1bNlSkjwuTC8rK1O7du00c+bMctu54YYb3J//+GL2S30d/pcf1r7++usegSmp3DtGL/W1A1A9OL0IXENuuukmXbhwQefOnZN0MUD++6Ly0tJS5ebmerWtXr16SZI2bNig1atXKzo62uOoy4+FhITorrvu0urVq7V69Wp16tRJzZs3dz/+5ZdfasiQIYqIiNDNN9+sevXqlbvg3Rv5+fkeR8e2b9+usrIyORwO932DBw/W+++/r2XLlunGG2/UL3/5y8tuz+l0yuFw6K233ip3MfuPtW/fXocOHVKjRo3UsmVLj/+8fTfn9ddfr+DgYI9TwZZlafv27e7bDodDtWvX1rfffltuPz8+0gXg6kF0ATXQiRMnNGzYMK1cuVK7d+/W4cOH9f777+utt95St27dVL9+fUlyR9CWLVu0Z88ePfPMM14fWQoMDNR9992n119/XTt37rzsNVH/rV+/flqzZo2ysrLKrW/VqpVWrVqlvXv3avv27Ro/fvxP+vEGderU0cSJE7Vr1y5lZ2crOTlZERER7iNWktS9e3c1bNhQc+bM0YABAy57gbx08SjUtGnTdOjQIcXGxmrdunXKzc3Vvn37lJGRoaNHj7qfHx0drcaNG2vMmDH64osvdPjwYW3dulXTpk3zeAdjRYYNG6a33npLH3zwgfbv36+pU6d6BGj9+vU1YsQITZ8+Xe+++64OHjyoXbt26W9/+xvvUASuYpxeBGqgevXq6bbbbtOiRYt06NAhnTt3TqGhoYqKitKjjz7qXveHP/xB33zzjcaMGaO6detq9OjRKigo8Ho//fr103vvvaf27dt7HEm6nPvuu08pKSkqLi5Wnz59PB574YUXNGnSJA0YMEAhISEaO3asTpw44f2L/j/NmjVT3759NXr0aJ04cULdu3fX1KlTPdb4+flpwIAB7uiqSHh4uP7+97/rz3/+s6ZMmaLjx48rMDBQbdu21fjx4zVo0CBJF0/lLV68WK+88ooef/xxnT59WiEhIbrzzjvVoEEDr1/DiBEjdPz4cT333HOSLr77Mzo6Wvv373eveeKJJ3TjjTdq/vz5Sk5OVv369eV0OjVy5Eiv9wPALD/rSi4kAIAaIikpSYcOHdKCBQuqexQA1whOLwK4ppw+fVqff/65Vq5cqd/97nfVPQ6AawinFwFcU8aMGaPt27dr4MCBioiIqO5xAFxDOL0IAABgAKcXAQAADLgqouvChQs6cuSILly4UN2jAAAAVImrIrqOHj2qXr16uX/FBQAAQE1zVUQXAABATUd0AQAAGEB0AQAAGEB0AQAAGEB0AQAAGEB0AQAAGEB0AQAAGEB0AQAAGEB0AQAAGEB0AQAAGEB0AQAgafPmzZowYYI2b95c3aOghgqo7gEAALgaLFy4UHv27NGZM2d01113Vfc4qIE40gUAgKQzZ854fAQqG9EFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgQIA3i3Jzc5WQkKCTJ0+qYcOGSk1NVVhYmMea2bNna8mSJQoJCZEkde7cWUlJSZU+MAAAgC/yKrqSkpIUFxenmJgYrVy5UomJiVq0aFG5df3799fEiRMrfUgAAABfV+HpxcLCQuXk5CgqKkqSFBUVpZycHBUVFVX5cAAAADVFhdGVl5en0NBQ2Ww2SZLNZlNISIjy8vLKrc3KylJ0dLRGjBih7Ozsyp8WAK5yZRfOV/cIwDXJF/7ueXV60RsPPfSQRo8erVq1aunTTz/VmDFjtGbNGjVq1KiydgEAVz3/gFr6cvrI6h4DP0HpiXz3R76Gvuf2p96q7hEqVOGRLrvdrvz8fLlcLkmSy+VSQUGB7Ha7x7rg4GDVqlVLktS9e3fZ7Xbt2bOnCkYGAADwPRVGV+PGjeV0OpWZmSlJyszMlNPpVFBQkMe6/Px89+e7du3SN998o1atWlXyuAAAAL7Jq9OLycnJSkhI0Lx589SgQQOlpqZKkuLj4zVu3Dh17NhRM2bM0M6dO+Xv769atWpp+vTpCg4OrtLhAQAAfIVX0eVwOJSRkVHu/rS0NPfnP4QYAAAAyuMn0gMAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAICkwwN/jI1DZ+D8LAABJ993USK0b1dF9NzWq7lFQQwVU9wAAAFwNnMF15QyuW91joAbjSBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABRBcAAIABXkVXbm6uYmNjFRkZqdjYWB04cOCya/fv369bb71VqamplTUjAACAz/MqupKSkhQXF6e1a9cqLi5OiYmJl1zncrmUlJSk3r17V+qQAAAAvq7C6CosLFROTo6ioqIkSVFRUcrJyVFRUVG5tW+++aYiIiIUFhZW6YMCAAD4sgqjKy8vT6GhobLZbJIkm82mkJAQ5eXleazbvXu3Nm3apOHDh1fJoAAAAL4soDI2cv78eU2aNEkvvviiO84AAADw/1UYXXa7Xfn5+XK5XLLZbHK5XCooKJDdbnevOXbsmA4dOqRRo0ZJkk6dOiXLslRcXKznn3++6qYHAADwERVGV+PGjeV0OpWZmamYmBhlZmbK6XQqKCjIvaZp06basmWL+/bs2bN15swZTZw4sWqmBgAA8DFevXsxOTlZ6enpioyMVHp6ulJSUiRJ8fHx2rFjR5UOCAAAUBN4dU2Xw+FQRkZGufvT0tIuuf6xxx77eVMBAADUMPxEegAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAMCvFmUm5urhIQEnTx5Ug0bNlRqaqrCwsI81ixfvlwLFy6Uv7+/ysrKNGjQIA0bNqwqZgYAAPA5XkVXUlKS4uLiFBMTo5UrVyoxMVGLFi3yWBMZGakBAwbIz89PxcXFio6O1h133KF27dpVyeAAAAC+pMLTi4WFhcrJyVFUVJQkKSoqSjk5OSoqKvJYV79+ffn5+UmSSkpKdP78efdtAACAa12F0ZWXl6fQ0FDZbDZJks1mU0hIiPLy8sqt/eijj9S3b1/96le/0siRI9W2bdvKnxgAAMAHVeqF9L169VJWVpbWrl2rlStXav/+/ZW5eQAAAJ9VYXTZ7Xbl5+fL5XJJklwulwoKCmS32y/7nKZNm6pjx476+OOPK21QAAAAX1ZhdDVu3FhOp1OZmZmSpMzMTDmdTgUFBXms27dvn/vzoqIibdmyRW3atKnkcQEAAHyTV+9eTE5OVkJCgubNm6cGDRooNTVVkhQfH69x48apY8eOWrZsmT799FMFBATIsiwNGTJEd999d5UODwAA4Cu8ii6Hw6GMjIxy96elpbk/f+aZZypvKgAAgBqGn0gPAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgANEFAABgQIA3i3Jzc5WQkKCTJ0+qYcOGSk1NVVhYmMeauXPnas2aNbLZbAoICND48eN1zz33VMXMAAAAPser6EpKSlJcXJxiYmK0cuVKJSYmatGiRR5rwsPDNWLECF133XXavXu3hgwZok2bNqlOnTpVMjgAAIAvqfD0YmFhoXJychQVFSVJioqKUk5OjoqKijzW3XPPPbruuuskSW3btpVlWTp58mQVjAwAAOB7KoyuvLw8hYaGymazSZJsNptCQkKUl5d32eesWLFCLVq0UJMmTSpvUgAAAB/m1enFK/HFF1/otdde0/z58yt70wAAAD6rwiNddrtd+fn5crlckiSXy6WCggLZ7fZya7Ozs/WnP/1Jc+fOVevWrSt/WgAAAB9VYXQ1btxYTqdTmZmZkqTMzEw5nU4FBQV5rNu+fbvGjx+vWbNmqX379lUzLQAAgI/y6ud0JScnKz09XZGRkUpPT1dKSookKT4+Xjt27JAkpaSkqKSkRImJiYqJiVFMTIy+/vrrqpscAADAh3h1TZfD4VBGRka5+9PS0tyfL1++vPKmAgAAqGH4ifQAAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF3wOZs3b9aECRO0efPm6h4FAACvBVT3AMCVWrhwofbs2aMzZ87orrvuqu5xAADwCke64HPOnDnj8REAAF9AdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhwzUbXufOu6h4BuCbxdw/Ateqa/d2LtWvZFPfU4uoeAz/B8eOnJUlHj5/ma+iDlkz/bXWPAADV4po90gUAAGAS0QUAAGAA0QUAAGAA0QUAAGAA0QUAAGAA0QUAAGAA0QUAAGAA0QWf42er5fERAABfQHTB59Rv2lm16jdR/aadq3sUAAC85lV05ebmKjY2VpGRkYqNjdWBAwfKrdm0aZMGDBigDh06KDU1tbLnBNwCb2iuoLYPKPCG5tU9CgAAXvMqupKSkhQXF6e1a9cqLi5OiYmJ5dY0b95cU6ZM0SOPPFLpQwIAAPi6CqOrsLBQOTk5ioqKkiRFRUUpJydHRUVFHutatmypW265RQEB1+yvcwQAALisCqMrLy9PoaGhstlskiSbzaaQkBDl5eVV+XAAAAA1BRfSAwAAGFBhdNntduXn58vlckmSXC6XCgoKZLfbq3w4AACAmqLC6GrcuLGcTqcyMzMlSZmZmXI6nQoKCqry4QAAAGoKr04vJicnKz09XZGRkUpPT1dKSookKT4+Xjt27JAkbdu2TT169NCCBQu0dOlS9ejRQxs3bqy6yQEAAHyIV281dDgcysjIKHd/Wlqa+/MuXbrok08+qbzJAAAAahAupAcAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADDAq+jKzc1VbGysIiMjFRsbqwMHDpRb43K5lJKSot69e+vXv/61MjIyKntWAAAAn+VVdCUlJSkuLk5r165VXFycEhMTy61ZvXq1Dh06pH/84x9atmyZZs+erSNHjlT6wAAAAL4ooKIFhYWFysnJ0YIFCyRJUVFRev7551VUVKSgoCD3ujVr1mjQoEHy9/dXUFCQevfurQ8++EAjR46scAiXyyVJOnr06E99HT9J6ZmTRvcHQNfEP8aOnS6p7hGAa051fG9p0qSJAgIqTCm3Clfm5eUpNDRUNptNkmSz2RQSEqK8vDyP6MrLy1PTpk3dt+12u9cRdezYMUnSb3/7W68HB+Cben04q7pHAFATvdPL+C4/+ugj/eIXv/B6vfd5VoU6dOigxYsXKzg42B13AAAAV7MmTZpc0foKo8tutys/P18ul0s2m00ul0sFBQWy2+3l1n377bcKDw+XVP7I1/9Sp04ddenS5YoGBwAA8CUVXkjfuHFjOZ1OZWZmSpIyMzPldDo9Ti1K0v3336+MjAyVlZWpqKhI69atU2RkZNVMDQAA4GP8LMuyKlq0b98+JSQk6NSpU2rQoIFSU1PVunVrxcfHa9y4cerYsaNcLpcmT56sTz/9VJIUHx+v2NjYKn8BAAAAvsCr6AIAAMDPw0+kBwAAMIDoAgAAMIDoAgAAMIDoAgAAMIDoAgAAMIDoQo0we/ZspaamVvcYAKrJunXr1KdPH/Xv31/79++v0n0lJCQoPT29SveBmumq+DVAAAD8HEuXLtW4cePUp0+f6h4FuCyiC9Wubdu2euKJJ7Ru3TqdPHlSU6ZM0WeffaaNGzfqwoULeu211+RwOHTs2DFNmDBB33//vUpLS3XvvffqqaeeuuQ209LStHbtWrlcLoWGhur5559XcHCw4VcGwIQXXnhBX375pXJzc7VkyRI9+eSTevnll/X9999LksaNG6eIiAgdOXJEv/nNbzR48GBt3LhRJSUlevnll7V06VJ99dVXqlOnjubNm6fg4GB9/fXXSklJ0dmzZ1VaWqrBgwdr+PDh5fZ97tw5zZw5U1u3btX58+fVpk0bJScnq169eob/FOATLKCatWnTxkpPT7csy7LWrFlj3XbbbdaGDRssy7KsN9980/rjH/9oWZZllZSUWMXFxZZlWda5c+esoUOHWv/85z8ty7KsWbNmWdOmTbMsy7JWrFhhPffcc5bL5bIsy7IWL15sTZgwweRLAmDYkCFDrPXr11vfffedFRMTY+Xn51uWZVn5+fnWPffcY3333XfW4cOHrTZt2ri/v6SlpVm33367lZOTY1mWZSUlJVkzZsywLMuyTp8+bZWWllqWZVnFxcVWnz59rL1791qWZVkTJ0603n77bcuyLGvu3LnW3Llz3XNMnz7dvQ3gxzjShavCD6cE2rdvL0mKiIiQJHXo0EEffvihJMnlcmn69OnKzs6WZVk6fvy4du/erR49enhsa/369fr3v/+tBx980P28+vXrG3olAKpTdna2jhw5ovj4ePd9fn5+OnjwoBo1aqS6deu6v7+0b99eTZo0kdPpdN/+7LPPJEklJSVKTk7W119/LT8/PxUUFGj37t1yOBwe+1u/fr2Ki4u1du1aSRePfLVr187AK4UvIrpwVQgMDJQk+fv7q3bt2u77/f39deHCBUnSggULdOrUKWVkZCgwMFCTJk1SaWlpuW1ZlqVHH31UAwcONDM8gKuGZVlq27atFi9eXO6xI0eOlPv+8t+3bTabXC6XJGnGjBkKDg7WtGnTFBAQoBEjRlz2+01SUpK6detWBa8GNQ3vXoTPOH36tIKDgxUYGKj8/Hx99NFHl1zXs2dPLVmyRN99952ki//y3L17t8lRAVSTTp066eDBg9q8ebP7vu3bt8u6wl8zfPr0aTVp0kQBAQH6z3/+o23btl1yXc+ePbVw4UKVlJRIkoqLi7Vv376f/gJQo3GkCz5j6NChevzxx9W/f381adLksv+y7N+/v06ePKkhQ4ZIuvgv0YcffphD/sA14IYbbtC8efP00ksv6YUXXtD58+fVvHlzvfHGG1e0nUcffVRPPfWUVq1apRYtWqhr166XXDdq1CjNmTNHAwcOlJ+fn/z8/DR27NhypyEBSfKzrjT/AQAAcMU4vQgAAGAA0QUAAGAA0QUAAGAA0QUAAGAA0QUAAGAA0QUAAGAA0QUAAGDA/wNRxDPm7TSx7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(10,5)})\n",
    "sns.set_style(\"white\")\n",
    "plt.title(\"Survival by Gender\", {\"fontsize\": 14})\n",
    "sns.barplot(x=data[\"Sex\"], y=data[\"Survived\"])\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>Males seem to have a significantly lower chance to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_groups = data.groupby(pd.cut(data[\"Age\"], [0, 10, 18, 40, 60, 100])).mean()\n",
    "plt.title(\"Survival by Age\", {\"fontsize\": 14})\n",
    "sns.barplot(x=age_groups.index, y=age_groups[\"Survived\"])\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>Children below 10 also seem to have better chances. The rate of survival decreases with increasing age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Survival by Passenger Class\", {\"fontsize\": 14})\n",
    "sns.barplot(x=data[\"Pclass\"], y=data[\"Survived\"])\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>First class has better survival rates than the second and third."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAFCCAYAAADL6mj4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X1UlGXi//EPDJK26iokNPhEYtKo2Kb2YGqZT1gOoqTRUlZfErfjqptWK7lfeSjbpKw2Sd2TlS2xbS5riYLmmtkqrmFubLqiHhexrEZIiKNWpg7z+6Nf8w1RZ0TmGkffr3M8y8xcc9/X7H0d9r333DMEuVwulwAAAOBTwf6eAAAAwKWA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6AIAADCA6ALgVxMnTtQTTzzRrNscOnSoXn311TM+npubK7vd3qz7BABPQvw9AQD+VVtbqwULFmjjxo2qrq5W27ZtdfXVV2vy5MkaOHCgz/efm5urkJCL41fRxIkTtXXr1kb3f/TRR2rbtq0fZgTgQnJx/KYD0GTTpk3Td999p6eeekpdunRRTU2NPvroI9XV1Z3Xdo8fP67Q0FCP49q1a3de+7nQJCUlaebMmQ3ua9OmTZO25XK5dPLkSbVo0aI5pgbAz3h7EbiEHT58WNu2bdOjjz6qAQMGqGPHjurTp48efPBBjR492j3udG/Xnfq24NChQ5Wbm6vHH39c/fv316OPPqrk5GTNmzevwfOOHj2qPn36aN26dY2289xzzykpKanRPO+++27NnTtXkrR9+3alpqbqxhtvVN++ffXLX/5SZWVlTXr9BQUFGjJkiPr06aMpU6aotrZW0g9npnr16qWvvvqqwfgXXnhBCQkJZ91mq1at1KFDhwb/goKCJEnvvPOOkpKSdN111+nmm2/Www8/rOrqavdz//nPfyo2NlYbN25UUlKS4uLitGXLFknSe++9p3HjxikuLk5Dhw7VH/7wBx0/frxJrxuAfxBdwCXs8ssv1+WXX673339f33///Xlvb+nSperWrZuWL1+umTNnasyYMSouLlZ9fb17zNq1a9WyZUvdeuutjZ6fmJionTt3qqKiwn3fgQMHVFZWpjFjxkiSvvnmG40ZM0ZvvvmmCgoKZLPZNHnyZHcweeuLL77QypUrtWjRIi1dulSffvqpZs+eLUm6/vrr1blzZ61YscI9vr6+XitWrND48ePPaT8/dfLkSf3mN7/RypUrtXjxYh06dEiPPPJIo3Hz58/XI488ojVr1qh37976xz/+oVmzZmnixIkqLi7WU089pdWrV2vBggVNngsA84gu4BIWEhKiefPmaeXKlerfv7+Sk5OVk5OjTz75pEnbu+GGG5SWlqauXbsqOjpad9xxh77++muVlpa6x6xatUqjRo067VuP3bt3l81m06pVqxqMj46OVp8+fSRJAwYM0NixYxUTE6OYmBjNmTNHl112mTZt2nROcz127JhycnLUs2dP9evXT9nZ2dqwYYP2798vSZowYYLefvtt9/hNmzappqbGHX9n8te//lXXXXed+19GRob7sQkTJujWW29V586dde211yojI0Nbt25tdEZt+vTpGjhwoDp37qywsDAtXrxYkydPVlJSkrp06aIBAwZo5syZ+stf/nJOrxmAf3FNF3CJi4+P15AhQ7Rt2zaVlZWppKREr732mmbMmKGHHnronLbVu3fvBrfbt2+vQYMGaeXKlRowYICqq6tVWlqqqVOnnnEbP57FevjhhyX9EF0/DZ2amhq9+OKLKi0t1aFDh1RfX69jx47J4XCc01wjIyMVFRXlvn3ttdcqODhYFRUVio6O1rhx4/TCCy/o448/Vt++fbV8+XINHz5c7du3P+t2b7/99gavr3Xr1u6fd+zYoYULF2rPnj2qq6uTy+WSJDkcDnXo0ME9Li4ursE2//Of/6i8vFx//OMf3ff9+Lpra2sVFhZ2Tq8dgH8QXQB02WWXaeDAgRo4cKCmTp2q3/3ud3rppZeUmpqq0NBQBQUFuQPhRydOnGi0nVatWjW6b8yYMZozZ46ysrJUXFwsq9Wqfv36nXEudrtdzz77rMrKyhQaGqp9+/Y1iK5Zs2appqZGjz/+uDp27KjQ0FA98MADp53P+QgLC9PQoUO1fPlyXXXVVXr//fcbRM+ZtGnTRl27dm10/9GjRzVp0iQNGjRIzz77rNq3b6+amhpNnDix0bVZp/vvcdq0aRo5cmSj+3/+85+fw6sC4E9EF4BGunfvrpMnT7o/gRgWFtbgLbDvv/9elZWV6tmzp8dtDRs2THPmzNGGDRu0atUqJSQkuC8sP52IiAjddNNNWrVqlUJDQ3Xdddepc+fO7sf/9a9/6X//9381ZMgQSdKhQ4cavT3njaqqKjkcDlmtVkk/XKBfX1+vmJgY95i77rpL06dPV+fOnXXFFVfo5ptvPuf9/KiiokJ1dXV69NFH3fvcs2ePV8+12WyqrKw8bcwBCBxc0wVcwr7++mvdd999Kiws1O7du3XgwAGtWbNGr7zyigYMGOB+a+zHCCotLdXevXs1e/Zsr88sXXbZZRo5cqQWL16snTt3erwmSvrh7Njq1atVXFzcaPxVV12llStX6r///a+2b9+uGTNmNOkrFVq2bKlZs2Zp165dKisrU1ZWloYMGaLo6Gj3mIEDB6pdu3Z66aWXlJSUpODgpv/K7Nixo1q0aKE33nhDBw4c0IYNG5Sbm+vVc6dOnarCwkLl5uZq7969qqio0Jo1azR//vwmzweAeUQXcAn72c9+pl/84hfKy8vTxIkTZbfb9cILL7j/80e/+tWvdNNNN2nKlClKTU1V37591atXL6/3M2bMGO3evVu9evVqcCbpTEaOHKljx47p66+/1u23397gsd///vf69ttv3d+Hdeedd6pjx47ev+j/r2PHjho9erQeeugh3X///erUqZOefvrpBmOCgoKUlJSkkydPnvarLM7FFVdcoXnz5mnt2rW64447tHjxYqWnp3v13FtvvVWLFy/W5s2bNX78eE2YMEGvvPKK+4wZgMAQ5Dr1Qg0AgFtmZqY+++wzLV261N9TARDgONMFAKdx5MgRbdmyRYWFhbr//vv9PR0AFwEupAeA05gyZYq2b9+u8ePHuy/aB4DzwduLAAAABvD2IgAAgAEXRHSdPHlSn3/+uU6ePOnvqQAAAPjEBRFdBw8e1LBhw3Tw4EF/TwUAAMAnLojoAgAAuNgRXQAAAAYQXQAAAAYQXQAAAAYQXQAAAAYQXQAAAAYQXQAAAAYQXQAAAAYQXQAAAAYQXQAAAAZ4FV2VlZVKTk5WfHy8kpOTtX///tOOW716tRISEmS325WQkKBDhw4151wBAAACVog3gzIzM5WSkqLExEQVFhYqIyNDeXl5Dcbs2LFDL730kv70pz+pQ4cOOnLkiEJDQ30yaQDwteMnTyg0pIW/p4Em4vjhQuQxumpqalReXq6lS5dKkux2u5588knV1tYqLCzMPe71119XamqqOnToIElq06aNj6YMAL4XGtJCDyz9jb+ngSZ6/X9e9PcUgEY8vr3ocDgUGRkpi8UiSbJYLIqIiJDD4WgwrqKiQgcOHNA999yjcePGadGiRXK5XL6ZNQAAQIDx6u1FbzidTu3Zs0dLly7V8ePHNWnSJEVFRWns2LHNtQsAAICA5fFMl9VqVVVVlZxOp6Qf4qq6ulpWq7XBuKioKI0aNUqhoaFq3bq1hg0bpu3bt/tm1gAAAAHGY3SFh4fLZrOpqKhIklRUVCSbzdbgei7ph2u9SkpK5HK5dOLECX344Ye65pprfDNrAACAAOPVV0ZkZWUpPz9f8fHxys/PV3Z2tiQpLS1NO3bskCSNHj1a4eHhuuOOOzR27Fh1795d48eP993MAQAAAkiQ6wK42v3zzz/XsGHDtH79enXq1Mnf0wEASeLTiwGMTy/iQsQ30gMAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABgQ4s2gyspKpaenq66uTu3atVNOTo6io6MbjMnNzdWbb76piIgISVLfvn2VmZnZ7BMGAAAIRF5FV2ZmplJSUpSYmKjCwkJlZGQoLy+v0bixY8dq1qxZzT5JAACAQOfx7cWamhqVl5fLbrdLkux2u8rLy1VbW+vzyQEAAFwsPEaXw+FQZGSkLBaLJMlisSgiIkIOh6PR2OLiYiUkJCg1NVVlZWXNP1sAAIAA5dXbi964++679dBDD6lFixbavHmzpkyZotWrV6t9+/bNtQsAAICA5fFMl9VqVVVVlZxOpyTJ6XSqurpaVqu1wbgOHTqoRYsWkqSBAwfKarVq7969PpgyAABA4PEYXeHh4bLZbCoqKpIkFRUVyWazKSwsrMG4qqoq98+7du3SF198oauuuqqZpwsAABCYvHp7MSsrS+np6Vq0aJHatm2rnJwcSVJaWpqmT5+uuLg4Pf/889q5c6eCg4PVokULPfPMM+rQoYNPJw8AABAovIqumJgYFRQUNLp/yZIl7p9/DDEAAAA0xjfSAwAAGEB0AQBwnpzHT/h7Cmgik8eu2b4yAgCAS5UltIVW3/c//p4GmuCOvKXG9sWZLgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAOILgAAAAO8iq7KykolJycrPj5eycnJ2r9//xnH7tu3T9dee61ycnKaa44AAAABz6voyszMVEpKitauXauUlBRlZGScdpzT6VRmZqaGDx/erJMEAAAIdB6jq6amRuXl5bLb7ZIku92u8vJy1dbWNhr78ssva8iQIYqOjm72iQIAAAQyj9HlcDgUGRkpi8UiSbJYLIqIiJDD4Wgwbvfu3SopKdEDDzzgk4kCAAAEspDm2MiJEyc0Z84cPf300+44AwAAwP/xGF1Wq1VVVVVyOp2yWCxyOp2qrq6W1Wp1j/nqq6/02WefafLkyZKkw4cPy+Vy6ejRo3ryySd9N3sAAIAA4TG6wsPDZbPZVFRUpMTERBUVFclmsyksLMw9JioqSqWlpe7bubm5+vbbbzVr1izfzBoAACDAePXpxaysLOXn5ys+Pl75+fnKzs6WJKWlpWnHjh0+nSAAAMDFwKtrumJiYlRQUNDo/iVLlpx2/LRp085vVgAAABcZvpEeAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILAADAAKILl5T6kyf8PQU0EccOQKAL8fcEAJOCQ1roX89M8vc00AT9fvuKv6cAAOeFM10AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGEF0AAAAGhHgzqLKyUunp6aqrq1O7du2Uk5Oj6OjoBmOWL1+u119/XcHBwaqvr9eECRN03333+WLOAAAAAcer6MrMzFRKSooSExNVWFiojIwM5eXlNRgTHx+vpKQkBQUF6ejRo0pISNANN9yga665xicTBwAACCQe316sqalReXm57Ha7JMlut6u8vFy1tbUNxrVu3VpBQUGSpGPHjunEiRPu2wAAAJc6j9HlcDgUGRkpi8UiSbJYLIqIiJDD4Wg0dv369Ro9erRuu+02TZo0SbGxsc0/YwAAgADUrBfSDxs2TMXFxVq7dq0KCwu1b9++5tw8AABAwPIYXVarVVVVVXI6nZIkp9Op6upqWa3WMz4nKipKcXFx+uCDD5ptogAAAIHMY3SFh4fLZrOpqKhIklRUVCSbzaawsLAG4yoqKtw/19bWqrS0VD169Gjm6QIAAAQmrz69mJWVpfT0dC1atEht27ZVTk6OJCktLU3Tp09XXFycli1bps2bNyskJEQul0v33nuvBg0a5NPJAwAABAqvoismJkYFBQWN7l+yZIn759mzZzffrAAAAC4yfCM9AACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAUQXAACAAQEfXcdPOP09BZwHjh8A4FIR4u8JnK/QFhal/PbP/p4GmujNZ+7x9xQAADAi4M90AQAABAKvznRVVlYqPT1ddXV1ateunXJychQdHd1gzMKFC7V69WpZLBaFhIRoxowZGjx4sC/mDAAAEHC8iq7MzEylpKQoMTFRhYWFysjIUF5eXoMxffr0UWpqqlq1aqXdu3fr3nvvVUlJiVq2bOmTiQMAAAQSj28v1tTUqLy8XHa7XZJkt9tVXl6u2traBuMGDx6sVq1aSZJiY2PlcrlUV1fngykDAAAEHo/R5XA4FBkZKYvFIkmyWCyKiIiQw+E443NWrFihLl266Morr2y+mQIAAASwZv/04tatW/Xiiy/qtddea+5NAwAABCyPZ7qsVquqqqrkdP7wfUpOp1PV1dWyWq2NxpaVlemxxx7TwoUL1a1bt+afLQAAQIDyGF3h4eGy2WwqKiqSJBUVFclmsyksLKzBuO3bt2vGjBlasGCBevXq5ZvZAgAABCivvqcrKytL+fn5io+PV35+vrKzsyVJaWlp2rFjhyQpOztbx44dU0ZGhhITE5WYmKg9e/b4buYAAAABxKtrumJiYlRQUNDo/iVLlrh/Xr58efPNCgAA4CLDN9IDAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAY4FV0VVZWKjk5WfHx8UpOTtb+/fsbjSkpKVFSUpJ69+6tnJyc5p4nAABAQPMqujIzM5WSkqK1a9cqJSVFGRkZjcZ07txZc+fO1YMPPtjskwQAAAh0HqOrpqZG5eXlstvtkiS73a7y8nLV1tY2GNe1a1f17NlTISEhvpkpAABAAPMYXQ6HQ5GRkbJYLJIki8WiiIgIORwOn08OAADgYsGF9AAAAAZ4jC6r1aqqqio5nU5JktPpVHV1taxWq88nBwAAcLHwGF3h4eGy2WwqKiqSJBUVFclmsyksLMznkwMAALhYePX2YlZWlvLz8xUfH6/8/HxlZ2dLktLS0rRjxw5J0rZt23TLLbdo6dKleuutt3TLLbdo06ZNvps5AABAAPHqo4YxMTEqKChodP+SJUvcP/fv318bN25svpkBAABcRLiQHgAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACiCwAAwACvoquyslLJycmKj49XcnKy9u/f32iM0+lUdna2hg8frhEjRqigoKC55woAABCwvIquzMxMpaSkaO3atUpJSVFGRkajMatWrdJnn32mv//971q2bJlyc3P1+eefN/uEAQAAAlGIpwE1NTUqLy/X0qVLJUl2u11PPvmkamtrFRYW5h63evVqTZgwQcHBwQoLC9Pw4cP17rvvatKkSR4n4XQ6JUkHDx5s0ov4/tu6Jj0P/uePMP/qyDHj+8T588daOVb3rfF9onn4Y73Ufs/vlkB0PmvlyiuvVEiIx5Ry8zjS4XAoMjJSFotFkmSxWBQRESGHw9EguhwOh6Kioty3rVar1xH11VdfSZLuueceryeOi8OwdQv8PQUEir8O8/cMEECG/ZH1Au88Oazpa2X9+vXq1KmT1+O9zzMf6t27t/785z+rQ4cO7rgDAAC4kF155ZXnNN5jdFmtVlVVVcnpdMpiscjpdKq6ulpWq7XRuC+//FJ9+vSR1PjM19m0bNlS/fv3P6eJAwAABBKPF9KHh4fLZrOpqKhIklRUVCSbzdbgrUVJGjVqlAoKClRfX6/a2lq99957io+P982sAQAAAkyQy+VyeRpUUVGh9PR0HT58WG3btlVOTo66deumtLQ0TZ8+XXFxcXI6nXriiSe0efNmSVJaWpqSk5N9/gIAAAACgVfRBQAAgPPDN9IDAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHQBAAAYQHT50NSpU7V9+3ZJP/x9yezsbA0fPlwjRoxQQUGBV9tYvny5EhISlJiYqISEBOXl5bkfO9s28/LyNGLECCUlJTXvi0Kz+en6aOpxPpuamhpNnjxZCQkJGjVqlLKysnTy5EmP22TtXDh+ukaaejzPpqSkRElJSerdu7dycnIaPLZw4UKNHj1aY8aMUVJSkjZt2uR+7LvvvtPDDz+sESNGaNSoUdqwYYP7sfnz52vIkCGaPn36+b58ePDT9eGLY3k2hYWFSkhIUM+ePZWfn9/gsQceeECJiYlKTEyU3W5XbGysdu/e7XF/l8TaccEn/v3vf7tSU1Pdt9955x1Xamqqy+l0umpqalyDBw92HThwwON2jhw54qqvr3f/PGTIENeuXbu82uaHH37oGjduXDO/MjSHU9fH+RznM5k7d65r3rx5LpfL5Tp+/Lhr/PjxruLiYq+2ydrxv1PXyPkczzPZv3+/a+fOna7nn3/eve0fbdy40fXtt9+6XC6Xa9euXa5+/fq5vvvuO5fL5XLl5ua6Zs+e7XK5XK7KykrXzTff7Dp69Kj7ucuXL3dNmzbtPF49PDl1ffjqWJ7Jnj17XHv37nU99thjrjfeeOOM49atW+caPXq0+/alvnY40+Ujy5Ytk91ud99evXq1JkyYoODgYIWFhWn48OF69913PW6ndevWCgoKkiQdO3ZMJ06ccN9u6jbhf6euD18c56CgIH3zzTeqr6/X8ePHdeLECUVGRp7XNmHOqWvEF8eza9eu6tmzp0JCGv9FuMGDB6tVq1aSpNjYWLlcLtXV1UmS1qxZo7vvvluSFB0drd69e2vjxo3n/ZrhvVPXh+lj2aNHD3Xv3l3BwWfPiL/97W+688473bcv9bVDdPnI1q1b3X+HUmr8tyitVqsOHjzo1bbWr1+v0aNH67bbbtOkSZMUGxt73tuEf526PqTmP85TpkxRZWWlBg0a5P7Xr1+/89omzDl1jfjzeK5YsUJdunRx/3HfL7/8Uh07dvTZ/uDZ6X6HeMPksTx06JC2bNmixMRE932X+tohunzk4MGDuuKKK5plW8OGDVNxcbHWrl2rwsJC7du3r1m2C/853fpo7uP87rvvKjY2ViUlJdq4caO2bdvG2awAcuoa8dfx3Lp1q1588UU999xzPt8XvNeU/40xfSzfeecdDR48uNHfar6UEV0+0rJlS33//ffu21arVV9++aX7tsPhcP8/DW9FRUUpLi5OH3zwQbNtE/5x6vr4qeY6zvn5+RozZoyCg4PVpk0bDR06VKWlpee1TZhz6hrxx/EsKyvTY489poULF6pbt27u+6OiovTFF180+/7gvbP9DjkdfxzLt99+u8Fbi77eXyAgunykR48eqqysdN8eNWqUCgoKVF9fr9raWr333nuKj4+XJK1bt06//e1vT7udiooK98+1tbUqLS1Vjx49PG4TF7ZT10dTj/PZ1k6nTp3c10ocP35cW7Zs0dVXX+1xm7gwnLpGmno8z7ZGzmb79u2aMWOGFixYoF69ejV4bNSoUVq2bJkkaf/+/dqxY4cGDx7cpNeJpjl1fZxNU49lfn5+k8+Kffzxxzpy5IhuueUWr/d3KWh8xR2axciRI1VSUqIbb7xRkpSYmKhPPvlEI0eOlCT9+te/VufOnSVJn376qVq3bn3a7SxbtkybN29WSEiIXC6X7r33Xg0aNMjjNnFhO3V9NPU4n23tzJ49W5mZmUpISJDT6dSNN96ou+66y+M2cWE4dY009XiebY1s27ZNM2fO1NGjR+VyuVRcXKynnnpKgwcPVnZ2to4dO6aMjAz3+GeeeUaxsbF68MEHlZ6erhEjRig4OFhPPPHEGfcB3zh1ffjiWFZUVKhTp06n3X9RUZGeeeYZHT58WOvXr9fLL7+s1157Td27d5f0w1musWPHymKxNHjeJb92/PnRyYvZkSNHXHa73f2x3LOZOnWqVx/vPld87P/CdS7r42xYOxevC32NnM3F/rH/C0FzrY+zueeee1xHjhzx2fZP52JfO0Eul8vl7/C7WG3evFmRkZHu8jcpLy9Pb731lqxWq1599VXj+4dn/lwfZ8PauXCxCIXnAAAATElEQVRcqGvkbObPn69169bp+uuv19y5c/09nYtaIK6Ps7kU1g7RBQAAYAAX0gMAABhAdAEAABhAdAEAABhAdAEAABhAdAEAABjw/wAcWl2qCdTNxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fare_groups = data.groupby(pd.cut(data[\"Fare\"], [0,30,80,120, 170])).mean()\n",
    "plt.title(\"Survival by Fare\", {\"fontsize\": 14})\n",
    "sns.barplot(x=fare_groups.index, y=fare_groups[\"Survived\"])\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>Survival rates increse with higher fares, altough the passengers that payed the highest fares had a lower survival rate tha those with high to very high fares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Survival by Passenger Embark\", {\"fontsize\": 14})\n",
    "sns.barplot(x=data[\"Embarked\"], y=data[\"Survived\"])\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>Altough it looks like passengers that embarked in Cherbourg have higher survival rates, this is probably just a random occurance as it is unlikely that it really impacts ones ability to survive a ship crash by entering the ship at a different location ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"><b><font color=\"darkblue\"> Step 2: Feature Engineering</b></font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>We have found some major correlations just by exploring the data, altough some of our features created in the following steps were just ideas or were created after training some models to further enhance performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used multiple functions to transform the data set as this enhanced the readability and made the \n",
    "# process simpler. \n",
    "\n",
    "# this function will transform the \"Sex\" column from String to categorical, create an \"Age_missing\" column\n",
    "# that indicates whether the ages was missing in the data set (Maybe it could not be recovered because the\n",
    "# passenger died with his documents?) and whether the cabin number was missing (I decided to add this, maybe\n",
    "# passengers that survived were responsible for entering their cabin numbers)\n",
    "\n",
    "def cat_to_bool(df):\n",
    "    df[\"Female\"] = df[\"Sex\"].str.get_dummies().iloc[:,0]\n",
    "    df[\"Age_missing\"] = df[\"Age\"].isnull().astype(\"int64\")\n",
    "    df[\"Cabin_missing\"] = df[\"Cabin\"].isnull().astype(\"int64\")\n",
    "\n",
    "# the following functions are used to extract the title from the \"Name\" column of the dataset. Altough titles from \n",
    "# the test set were extracted, they were later dropped if they did not occur in the training set. \n",
    "\n",
    "def get_title(row):\n",
    "    words = row.split(\" \")\n",
    "    for word in words:\n",
    "        if word.endswith(\".\"):\n",
    "            return word[:-1]\n",
    "    return np.nan\n",
    "\n",
    "def extract_title(df):\n",
    "    df[\"Title\"] = df[\"Name\"].apply(get_title)\n",
    "    \n",
    "# similar to the title extraction, these two functions extract the last names of the passengers. It was assumed\n",
    "# that the last name was the first word in the \"Name\" column.\n",
    "\n",
    "def get_last_name(row):\n",
    "    words = row.split(\" \")\n",
    "    return words[0]\n",
    "    \n",
    "def extract_last_name(df):\n",
    "    df[\"Last_name\"] = df[\"Name\"].apply(get_last_name)\n",
    "\n",
    "# with the last names, it was possible to check wether a person of the same last name had survived the sinking.\n",
    "# this proved to be a useful feature later on.\n",
    "    \n",
    "def relative_survived(df):\n",
    "    last_name_survived = dict()\n",
    "    train = df[df[\"Set\"] == \"train\"]\n",
    "    for last_name in train[\"Last_name\"].unique():\n",
    "        last_name_df = train[train[\"Last_name\"] == last_name]\n",
    "        survived = last_name_df[\"Survived\"].sum()\n",
    "        last_name_survived[last_name] = int(survived)\n",
    "    df[\"Relative_survived\"] = df[\"Last_name\"].map(last_name_survived) - df[\"Survived\"]\n",
    "    df.loc[df[\"Relative_survived\"] > 0, \"Relative_survived\"] = 1\n",
    "    df.loc[df[\"Relative_survived\"] == 0, \"Relative_survived\"] = 0\n",
    "\n",
    "# next I added various other features:\n",
    "#     - a column that counts how many passengers had the same cabin an thus indicates if two passengers shared the\n",
    "#       same room\n",
    "#     - a column that contains the letter of the cabin, which stands for the titanics floors\n",
    "#     - a column that combines the \"Parch\" and \"SibSp\" columns to a column named \"Family_size\", \n",
    "#       as they contain very similar information\n",
    "#     - a column that states whether the passenger traveled alone\n",
    "#     - I normalized the \"Fare\" column by the distance that was traveled after the embarking. I assumed some \n",
    "#       distances for the whole trip by looking on a map and dividing the fares by different numbers. This did\n",
    "#       increase the correlation to the survival rate by a tiny amount, so I decided to keep this instead of\n",
    "#       the original \"Fare\" column\n",
    "#     - I also constructed a column \"Survivability_idx\" that combined some features into a more useful index; I\n",
    "#       decided to reduce the paid fare if the passenger was female in order to combat the already higher survival\n",
    "#       chance, and add some penalty if the passenger traveled alone. \n",
    "\n",
    "def add_cols(df):\n",
    "    train = df[df[\"Set\"] == \"train\"]\n",
    "    df[\"Cabin_counts\"] = df[\"Cabin\"].map(df[\"Cabin\"].value_counts())\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].str[0]\n",
    "    df[\"Family_size\"] = df[\"Parch\"] + df[\"SibSp\"] + 1\n",
    "    df[\"Alone\"] = df[\"Family_size\"] <= 1\n",
    "    df[\"Fare_distance\"] = df[\"Fare\"]\n",
    "    df.loc[df[\"Embarked\"] == \"S\",\"Fare_distance\"] = df.loc[df[\"Embarked\"] == \"S\",\"Fare_distance\"]/4.2\n",
    "    df.loc[df[\"Embarked\"] == \"C\",\"Fare_distance\"] = df.loc[df[\"Embarked\"] == \"C\",\"Fare_distance\"]/3.5\n",
    "    df.loc[df[\"Embarked\"] == \"Q\",\"Fare_distance\"] = df.loc[df[\"Embarked\"] == \"Q\",\"Fare_distance\"]/2.8\n",
    "    df[\"Survivability_idx\"] = (abs(df[\"Female\"] - 0.7)) * df[\"Fare_distance\"] + abs(df[\"Age\"] - 40) * (abs(df[\"Alone\"] - 0.6))\n",
    "\n",
    "# to fill in the missing ages, I used following function which uses the titles to get the mean age for that \n",
    "# corresponding title and fill all missing values belonging to that same title with this mean age.\n",
    "\n",
    "def guess_age(df):\n",
    "    title_ages = dict()\n",
    "    for title in df[\"Title\"].unique():\n",
    "        title_df = df[df[\"Title\"] == title]\n",
    "        title_ages[title] = title_df[\"Age\"].mean()\n",
    "    guessed_age = df[\"Title\"].map(title_ages)\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(guessed_age)\n",
    "\n",
    "# With this function, useless columns were dropped. I especially removed all non numeric columns and some columns\n",
    "# that came from test set transformations or generally had high correlations with other columns such as \"SibSp\",\n",
    "# \"Parch\" or \"Fare\"\n",
    "\n",
    "def drop_cols(df):\n",
    "    # dropping columns that are not useful or have already been converted\n",
    "    df = df.drop([\"PassengerId\", \"Name\", \"Sex\", \"Ticket\", \"Cabin\", \"Pclass\", \"Embarked\", \"Title\",\n",
    "                 \"Title_Mlle\", \"Title_Dona\", \"Cabin_T\", \"Last_name\",\n",
    "                 \"Title_Jonkheer\",\"Title_Mme\", \"Parch\", \"SibSp\", \"Cabin_missing\", \"Fare\",\n",
    "                  \"Cabin_F\", \"Title_Don\"\n",
    "                 ], axis=1, inplace=True)\n",
    "\n",
    "# This function was used to create dummy columns for categoric features.  \n",
    "\n",
    "def create_dummies(df):\n",
    "    df[[\"Class_\"+ str(s) for s in df[\"Pclass\"].dropna().unique()]] = pd.get_dummies(df[\"Pclass\"])\n",
    "    df[[\"Title_\"+ str(s) for s in df[\"Title\"].dropna().unique()]] = pd.get_dummies(df[\"Title\"])\n",
    "    df[[\"Cabin_\" + str(s) for s in df[\"Cabin\"].dropna().unique()]] = pd.get_dummies(df[\"Cabin\"])\n",
    "    #df[[\"Embarked_\" + str(s) for s in df[\"Embarked\"].dropna().unique()]] = pd.get_dummies(df[\"Embarked\"])\n",
    "\n",
    "# The remaining missing values were filled with fitting values.\n",
    "\n",
    "def replace_nan(df):\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(df[df[\"Set\"] == \"train\"].loc[:,\"Age\"].mean())\n",
    "    df[\"Cabin_counts\"] = df[\"Cabin_counts\"].fillna(-1)\n",
    "    df[\"Relative_survived\"] = df[\"Relative_survived\"].fillna(0)\n",
    "\n",
    "# combining all transformation functions:\n",
    "\n",
    "def transform_df(df):\n",
    "    cat_to_bool(df)\n",
    "    extract_title(df)\n",
    "    extract_last_name(df)\n",
    "    relative_survived(df)\n",
    "    guess_age(df)\n",
    "    add_cols(df)\n",
    "    create_dummies(df)\n",
    "    replace_nan(df)\n",
    "    drop_cols(df)\n",
    "    \n",
    "# Finally a function to ectract the numpy array used by the models from the Dataframe. This also took care\n",
    "# of separating training and test set again.\n",
    "def df_to_array(df):\n",
    "    train = df[df[\"Set\"] == \"train\"].drop(\"Set\", axis=1)\n",
    "    test = df[df[\"Set\"] == \"test\"].drop(\"Set\", axis=1)\n",
    "    y = train[\"Survived\"].values\n",
    "    X = train.drop([\"Survived\"], axis=1).values\n",
    "    X_test = test.drop([\"Survived\"], axis=1)\n",
    "    return X, y, X_test\n",
    "    \n",
    "transform_df(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>After all this feature engineering, let us look at the correlations of the created features:\n",
    "- The \"Title\" features are all over the place, I decided to largely ignore those correlations as those features are binary anyway\n",
    "- The \"Female\" column has the highest correlation with \"Survived\" in the whole dataset\n",
    "- The \"Fare_distance\" and \"Relative_survived\" aswell as \"Alone\" and \"Survivability_idx\" seem to be other useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived             1.000000\n",
       "Title_Col            0.549199\n",
       "Female               0.543351\n",
       "Title_Capt           0.339040\n",
       "Title_Lady           0.327093\n",
       "Class_2              0.322308\n",
       "Cabin_counts         0.311507\n",
       "Class_3              0.285904\n",
       "Fare_distance        0.260027\n",
       "Relative_survived    0.227130\n",
       "Alone                0.203367\n",
       "Cabin_E              0.175095\n",
       "Survivability_idx    0.170445\n",
       "Cabin_D              0.150716\n",
       "Cabin_A              0.145321\n",
       "Cabin_G              0.114652\n",
       "Class_1              0.093349\n",
       "Age_missing          0.092197\n",
       "Age                  0.087092\n",
       "Title_Major          0.085221\n",
       "Title_Sir            0.060095\n",
       "Cabin_B              0.057935\n",
       "Title_Countess       0.042470\n",
       "Title_Miss           0.042470\n",
       "Title_Dr             0.026456\n",
       "Title_Mr             0.026456\n",
       "Title_Master         0.026456\n",
       "Cabin_C              0.022287\n",
       "Family_size          0.016639\n",
       "Title_Ms             0.011329\n",
       "Title_Mrs            0.011329\n",
       "Title_Rev            0.008185\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transformed = data[data[\"Set\"] == \"train\"]\n",
    "train_transformed.corr()[\"Survived\"].abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>My next step was scaling the data. The features were on largely different scales and had to be normalized. I excluded all binary columns from this, as scaling those cold worsen our models performances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"Female\", \"Age_missing\", \"Relative_survived\", \"Alone\", \"Class_3\", \"Class_2\", \"Class_1\", \"Title_Mr\",\n",
    "           \"Title_Mrs\", \"Title_Ms\", \"Title_Major\", \"Title_Master\", \"Title_Miss\", \"Title_Rev\", \"Title_Dr\",\n",
    "           \"Title_Lady\", \"Title_Sir\", \"Title_Col\", \"Title_Capt\", \"Title_Countess\", \"Cabin_C\", \"Cabin_E\", \"Cabin_G\",\n",
    "           \"Cabin_D\", \"Cabin_A\", \"Cabin_B\"]\n",
    "\n",
    "data_cat = data[cat_cols]\n",
    "data_cat[[\"Survived\", \"Set\"]] = data[[\"Survived\", \"Set\"]] \n",
    "data_num = data.drop(cat_cols, axis=1)\n",
    "X_num, y, X_test_num = df_to_array(data_num)\n",
    "X_cat, throwaway, X_test_cat = df_to_array(data_cat)\n",
    "\n",
    "#print(data_num.drop([\"Survived\", \"Set\"], axis=1).columns)\n",
    "#print(data_cat.drop([\"Survived\", \"Set\"], axis=1).columns)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_num_scaled = scaler.fit_transform(X_num)\n",
    "X_scaled = np.c_[X_num_scaled, X_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 31) (891,)\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"><b><font color=\"darkblue\"> Step 3: Model Selection and Fine Tuning</b></font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>I decided to try different models, but settled on three main ones as they proved to be the most promising:\n",
    "- Logistic Regression\n",
    "- Random Forests\n",
    "- Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>Model 1 - Logistic Regression:\n",
    "- I used a mask to select the features used in my logistic regression model. In the following, all features\n",
    "are selected, as I decided to stop using LR and focus on Neural Nets and Random Forests. With the right features,\n",
    "the LR Model scored roughly 83% accuracy in cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'max_iter': 500}\n"
     ]
    }
   ],
   "source": [
    "lr_mask = [True, True, True, True, True, True, True, True, True, True,\n",
    "           True, True, True, True, True, True, True, True, True, \n",
    "           True, True, True, True, True, True, True, True, True, \n",
    "           True, True, True]\n",
    "\n",
    "lr_params = {\n",
    "    \"C\": [0.1, 0.3, 1],\n",
    "    \"max_iter\": [500]\n",
    "}\n",
    "lr_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "lr_grid = GridSearchCV(lr_clf, lr_params, cv=10, scoring=\"recall\")\n",
    "lr_grid.fit(X_scaled[:, lr_mask], y)\n",
    "print(lr_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7630082335964689\n"
     ]
    }
   ],
   "source": [
    "print(lr_grid.cv_results_[\"mean_test_score\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>Model 2 - Decision Trees:\n",
    "- I used scikit-learns SelectFromModel to get features that were useful in enhancing the decision trees impurity.\n",
    "This method automatically filtered out some useless features. I manually tuned the cutoff threshold as a hyperparameter to maximize the CV score of my model.\n",
    "- I used GridSearchCV in order to identify the best hyperparameters for my decision tree. In addition, I focused on maximizing the f1 score as I found that the accuracy was already pretty good on all hyperparameters.\n",
    "- The model was used in my first few submissions (gradually adding more feature engineering and Fine Tuning) and scored roughly 80% accuracy on the kaggle test set, which put me in the top 15% on the Leaderboard.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age' 'Cabin_counts' 'Family_size' 'Fare_distance' 'Survivability_idx'\n",
      " 'Female' 'Age_missing' 'Relative_survived' 'Alone' 'Class_3' 'Class_2'\n",
      " 'Class_1' 'Title_Lady' 'Title_Col' 'Title_Capt']\n"
     ]
    }
   ],
   "source": [
    "sel_clf = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold=\"0.3*mean\")\n",
    "sel_clf.fit(X_scaled, y)\n",
    "\n",
    "all_cols = list(data_num.drop([\"Survived\", \"Set\"], axis=1).columns) + list(data_cat.drop([\"Survived\", \"Set\"], axis=1).columns)\n",
    "sel_features = np.array(all_cols)[sel_clf.get_support()]\n",
    "print(sel_features)\n",
    "X_scaled = X_scaled[:, sel_clf.get_support()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'max_leaf_nodes': 37, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    \"n_estimators\": [200],\n",
    "    \"max_depth\": [6],\n",
    "    \"min_samples_leaf\": [2],\n",
    "    \"min_samples_split\": [5],\n",
    "    #\"max_features\": [14]\n",
    "    \"max_leaf_nodes\": [37]\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_grid = GridSearchCV(rf_clf, rf_params, cv= 10, scoring=\"f1_macro\")\n",
    "rf_grid.fit(X_scaled, y)\n",
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87192245]\n"
     ]
    }
   ],
   "source": [
    "print(rf_grid.cv_results_[\"mean_train_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8301679129949154\n"
     ]
    }
   ],
   "source": [
    "print(rf_grid.cv_results_[\"mean_test_score\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>The next step includes saving the predictions with the passenger Id's into a csv file that could be used to score the predictions using kaggles grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num = X_test_num.fillna(-1)\n",
    "X_test_cat = X_test_cat.fillna(-1)\n",
    "\n",
    "X_test_num_scaled = scaler.transform(X_test_num)\n",
    "X_test_scaled = np.c_[X_test_num_scaled, X_test_cat]\n",
    "X_test_scaled = X_test_scaled[:, sel_clf.get_support()]\n",
    "predictions_test = rf_grid.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "predicted = pd.DataFrame()\n",
    "predicted[\"PassengerId\"] = passenger_ids\n",
    "predicted[\"Survived\"] = predictions_test.astype(\"int32\")\n",
    "predicted.to_csv(\"preds.csv\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1\n",
       "5          897         0\n",
       "6          898         1\n",
       "7          899         0\n",
       "8          900         1\n",
       "9          901         0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = pd.read_csv(\"preds.csv\")\n",
    "testing.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><font color=\"#323231\"><i>Model 3 - Deep Neural Network:\n",
    "- I decided to give a Neural Network a try as my Random Forest was improving on the CV data but not on kaggles test set\n",
    "- The network was created in tensorflow to allow for more customization; I decided to use dropout and batch normalization in the network. The dropoout rate was tuned like a Hyperparameter\n",
    "- Weights were initialized using Xavier initialization\n",
    "- Since the dataset is rather small, I implemented Cross Validation to get a more robust estimate of the networks performance\n",
    "- For each fold, I stared with re-initializing the weights in order to prevent Overfitting. I also used slight l2 regularization and different dropout rates in the layers to reduce Overfitting\n",
    "- After the training and scoring for each fold is finished, the network trains for 400 iterations on all of the data in order to make most of it.\n",
    "- This Model scored better and worse on some folds, but could go up to 90% validation accuracy, averaging at around 84% during CV with low Overfitting. The predictions on the test data proved to be the best of all my models and scored 81.34% accuracy on kaggles grader, which puts it in the top 6% of models (at the time this notebook was written)\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = X_scaled.astype(\"float32\")\n",
    "y_train_ = y.astype(\"int32\").reshape(-1, 1)\n",
    "X_val_ = X_scaled.astype(\"float32\")\n",
    "y_val_ = y.astype(\"int32\").reshape(-1, 1)\n",
    "X_test_ = X_test_scaled.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train_.shape[1]\n",
    "n_hidden_1 = 400\n",
    "n_hidden_2 = 400\n",
    "n_outputs = 1\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "dropout_rate_0 = 0.2\n",
    "dropout_rate_1 = 0.5\n",
    "dropout_rate_2 = 0.15\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"neural_network\"):\n",
    "    xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "    \n",
    "    X_drop = tf.layers.dropout(X, dropout_rate_0, training=training)\n",
    "    \n",
    "    hidden_1 = tf.layers.dense(X_drop, n_hidden_1, kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01), kernel_initializer=xavier_init, name=\"hidden_1\")\n",
    "    bn1 = tf.layers.batch_normalization(hidden_1, training=training, momentum=0.9)\n",
    "    bn1_act = tf.nn.elu(bn1)\n",
    "    hidden_1_drop = tf.layers.dropout(bn1_act, dropout_rate_1, training=training)\n",
    "    \n",
    "    hidden_2 = tf.layers.dense(hidden_1_drop, n_hidden_2, kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01), kernel_initializer=xavier_init, name=\"hidden_2\")\n",
    "    bn2 = tf.layers.batch_normalization(hidden_2, training=training, momentum=0.9)\n",
    "    bn2_act = tf.nn.elu(bn2)\n",
    "    hidden_2_drop = tf.layers.dropout(bn2_act, dropout_rate_2, training=training)\n",
    "    \n",
    "    logits = tf.layers.dense(hidden_2_drop, n_outputs, kernel_initializer=xavier_init, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    #sigmoids = tf.nn.sigmoid(logits)\n",
    "    #loss = y * -tf.log(sigmoids) + 3 * (1 - y) * -tf.log(1 - sigmoids) + tf.losses.get_regularization_loss()\n",
    "    #loss = tf.reduce_mean(loss)\n",
    "    xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\") + tf.losses.get_regularization_loss()\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    predicted = tf.round(tf.nn.sigmoid(logits))\n",
    "    correct = tf.equal(predicted, y)\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    TP = tf.count_nonzero(predicted * y)\n",
    "    TN = tf.count_nonzero((predicted - 1) * (y - 1))\n",
    "    FP = tf.count_nonzero(predicted * (y - 1))\n",
    "    FN = tf.count_nonzero((predicted - 1) * y)\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    w = [v for v in tf.trainable_variables() if v.name == \"hidden_1/kernel:0\"][0]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Train_loss  3.2982535 Val_loss 3.8188324\n",
      "Epoch:  100  Train_loss  0.4352552 Val_loss 0.52110785\n",
      "Epoch:  200  Train_loss  0.4336008 Val_loss 0.5119908\n",
      "Epoch:  300  Train_loss  0.44887343 Val_loss 0.5273264\n",
      "\n",
      "Fold:  1\n",
      "Training Accuracy:  0.8451935  Validation Accuracy:  0.8333333\n",
      "Training F1:  0.7891156462585035  Validation F1:  0.8\n",
      "\n",
      "Epoch:  0  Train_loss  2.997153 Val_loss 3.2310205\n",
      "Epoch:  100  Train_loss  0.44759002 Val_loss 0.45628658\n",
      "Epoch:  200  Train_loss  0.45620748 Val_loss 0.45857835\n",
      "Epoch:  300  Train_loss  0.44954303 Val_loss 0.497711\n",
      "\n",
      "Fold:  2\n",
      "Training Accuracy:  0.8426966  Validation Accuracy:  0.87777776\n",
      "Training F1:  0.7913907284768212  Validation F1:  0.7441860465116279\n",
      "\n",
      "Epoch:  0  Train_loss  3.1932993 Val_loss 3.2805176\n",
      "Epoch:  100  Train_loss  0.43881238 Val_loss 0.5162769\n",
      "Epoch:  200  Train_loss  0.43383673 Val_loss 0.54330224\n",
      "Epoch:  300  Train_loss  0.43906426 Val_loss 0.53163\n",
      "\n",
      "Fold:  3\n",
      "Training Accuracy:  0.8489388  Validation Accuracy:  0.7777778\n",
      "Training F1:  0.7924528301886792  Validation F1:  0.7058823529411765\n",
      "\n",
      "Epoch:  0  Train_loss  3.284288 Val_loss 3.3646567\n",
      "Epoch:  100  Train_loss  0.43695742 Val_loss 0.4761194\n",
      "Epoch:  200  Train_loss  0.43607813 Val_loss 0.48467398\n",
      "Epoch:  300  Train_loss  0.43912348 Val_loss 0.5161547\n",
      "\n",
      "Fold:  4\n",
      "Training Accuracy:  0.8377029  Validation Accuracy:  0.84444445\n",
      "Training F1:  0.7619047619047619  Validation F1:  0.8372093023255814\n",
      "\n",
      "Epoch:  0  Train_loss  2.8823535 Val_loss 3.1259315\n",
      "Epoch:  100  Train_loss  0.44275016 Val_loss 0.49466464\n",
      "Epoch:  200  Train_loss  0.44924203 Val_loss 0.46120203\n",
      "Epoch:  300  Train_loss  0.45238054 Val_loss 0.47672933\n",
      "\n",
      "Fold:  5\n",
      "Training Accuracy:  0.8514357  Validation Accuracy:  0.84444445\n",
      "Training F1:  0.7863554757630161  Validation F1:  0.8\n",
      "\n",
      "Epoch:  0  Train_loss  2.8701928 Val_loss 2.879392\n",
      "Epoch:  100  Train_loss  0.44830865 Val_loss 0.43630174\n",
      "Epoch:  200  Train_loss  0.4512839 Val_loss 0.44003484\n",
      "Epoch:  300  Train_loss  0.45888245 Val_loss 0.46071738\n",
      "\n",
      "Fold:  6\n",
      "Training Accuracy:  0.8439451  Validation Accuracy:  0.8333333\n",
      "Training F1:  0.7818499127399651  Validation F1:  0.7540983606557377\n",
      "\n",
      "Epoch:  0  Train_loss  2.817634 Val_loss 2.8235216\n",
      "Epoch:  100  Train_loss  0.4394004 Val_loss 0.48008958\n",
      "Epoch:  200  Train_loss  0.4581528 Val_loss 0.53983164\n",
      "Epoch:  300  Train_loss  0.4343373 Val_loss 0.47047877\n",
      "\n",
      "Fold:  7\n",
      "Training Accuracy:  0.8426966  Validation Accuracy:  0.8111111\n",
      "Training F1:  0.7804878048780487  Validation F1:  0.7301587301587302\n",
      "\n",
      "Epoch:  0  Train_loss  2.808667 Val_loss 2.8438945\n",
      "Epoch:  100  Train_loss  0.45894983 Val_loss 0.50788254\n",
      "Epoch:  200  Train_loss  0.45693743 Val_loss 0.5061607\n",
      "Epoch:  300  Train_loss  0.44971475 Val_loss 0.4566218\n",
      "\n",
      "Fold:  8\n",
      "Training Accuracy:  0.8389513  Validation Accuracy:  0.8333333\n",
      "Training F1:  0.7794871794871795  Validation F1:  0.7368421052631579\n",
      "\n",
      "Epoch:  0  Train_loss  2.807343 Val_loss 2.5930867\n",
      "Epoch:  100  Train_loss  0.45892856 Val_loss 0.45141596\n",
      "Epoch:  200  Train_loss  0.4570354 Val_loss 0.4526779\n",
      "Epoch:  300  Train_loss  0.48014727 Val_loss 0.44373247\n",
      "\n",
      "Fold:  9\n",
      "Training Accuracy:  0.83021224  Validation Accuracy:  0.8888889\n",
      "Training F1:  0.7718120805369127  Validation F1:  0.84375\n",
      "\n",
      "Epoch:  0  Train_loss  2.7857528 Val_loss 2.5204391\n",
      "Epoch:  100  Train_loss  0.45284665 Val_loss 0.4141786\n",
      "Epoch:  200  Train_loss  0.46389502 Val_loss 0.42972913\n",
      "Epoch:  300  Train_loss  0.45913863 Val_loss 0.42274636\n",
      "\n",
      "Fold:  10\n",
      "Training Accuracy:  0.8458693  Validation Accuracy:  0.8625\n",
      "Training F1:  0.7848537005163512  Validation F1:  0.8070175438596492\n",
      "\n",
      "Training with all Data...\n",
      "Mean Training Acc.:  0.8427642  Mean Validation Acc.:  0.8406944  Mean Training F1:  0.7819710120750238  Mean Validation F1:  0.7759144441715661\n"
     ]
    }
   ],
   "source": [
    "def get_fold(fold, X=X_train_, y=y_train_, k_folds=10):\n",
    "    m = X.shape[0]\n",
    "    fold_size = np.ceil(m/k_folds)\n",
    "    if fold != (k_folds-1):\n",
    "        idx = slice(int(fold*fold_size), int((fold+1)*fold_size))\n",
    "    elif fold == (k_folds-1):\n",
    "        idx = slice(int(fold*fold_size), int(m-1))\n",
    "    else:\n",
    "        raise ValueError(\"Error at get_fold\", fold)\n",
    "        \n",
    "    X_val = X[idx, :]\n",
    "    y_val = y[idx, :]\n",
    "    X_train = np.delete(X, idx, axis=0)\n",
    "    y_train = np.delete(y, idx, axis=0)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "    \n",
    "n_epochs = 400\n",
    "k_folds = 10\n",
    "\n",
    "bn_updates = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    train_f1 = []\n",
    "    val_f1 = []\n",
    "    \n",
    "    init.run()\n",
    "    \n",
    "    for fold in range(0, k_folds+1):\n",
    "        init.run()\n",
    "        if fold < k_folds:\n",
    "            X_train, y_train, X_val, y_val = get_fold(fold=fold, k_folds=10)\n",
    "        if fold == k_folds:\n",
    "            print(\"Training with all Data...\")\n",
    "            X_train = X_train_\n",
    "            y_train = y_train_\n",
    "        for epoch in range(n_epochs):\n",
    "            sess.run([training_op, bn_updates], feed_dict={training: True, X: X_train, y: y_train})  \n",
    "            if epoch % 100 == 0:\n",
    "                #print(w.eval())\n",
    "                if fold < k_folds:\n",
    "                    print(\"Epoch: \", epoch, \" Train_loss \", loss.eval(feed_dict={X: X_train, y: y_train}), \"Val_loss\", loss.eval(feed_dict={X: X_val, y: y_val}))\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        f1_train = f1.eval(feed_dict={X: X_train, y: y_train})\n",
    "        f1_val = f1.eval(feed_dict={X: X_val, y: y_val})\n",
    "        \n",
    "        if fold < k_folds:\n",
    "            train_accs.append(acc_train)\n",
    "            val_accs.append(acc_val)\n",
    "            train_f1.append(f1_train)\n",
    "            val_f1.append(f1_val)\n",
    "            \n",
    "            print()\n",
    "            print(\"Fold: \", fold+1)\n",
    "            print(\"Training Accuracy: \", acc_train, \" Validation Accuracy: \", acc_val)\n",
    "            print(\"Training F1: \", f1_train, \" Validation F1: \", f1_val)\n",
    "            print()\n",
    "            \n",
    "    mean_train_acc = np.mean(train_accs)\n",
    "    mean_val_acc = np.mean(val_accs)\n",
    "    mean_train_f1 = np.mean(train_f1)\n",
    "    mean_val_f1 = np.mean(val_f1)\n",
    "    \n",
    "    predictions_test = predicted.eval(feed_dict={X: X_test_})\n",
    "    save_path = saver.save(sess, \"./my_model_final_3.ckpt\")\n",
    "    print(\"Mean Training Acc.: \", mean_train_acc, \" Mean Validation Acc.: \", mean_val_acc, \" Mean Training F1: \", mean_train_f1, \" Mean Validation F1: \", mean_val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame()\n",
    "predicted[\"PassengerId\"] = passenger_ids\n",
    "predicted[\"Survived\"] = predictions_test.astype(\"int32\")\n",
    "predicted.to_csv(\"preds_nn.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1\n",
       "5          897         0\n",
       "6          898         1\n",
       "7          899         0\n",
       "8          900         1\n",
       "9          901         0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = pd.read_csv(\"preds_nn.csv\")\n",
    "testing.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
